# ====================================================================================
# CI WORKFLOW - Continuous Integration Pipeline
# ====================================================================================
#
# IMPORTANT: Reusable Workflow Result Evaluation Bug (see #1065)
# -------------------------------------------------------------
# GitHub Actions has a known issue where jobs depending on reusable workflows may be
# incorrectly skipped, even when the upstream workflow completes successfully.
#
# WORKAROUND: When adding jobs that depend on reusable workflows (like cross_module_ci
# or package_* jobs), you MUST use this pattern:
#
#   if: ${{ always() && needs.upstream_job.result == 'success' && <your conditions> }}
#
# Rule: When adding job X that depends on reusable workflow Y:
#   1. Start with always()
#   2. Check needs.Y.result == 'success' for EACH reusable workflow dependency
#   3. Then add your business logic conditions (outputs, branch checks, etc.)
#
# See docs/github/workflows/ci/ci.md for detailed documentation and examples.
# ====================================================================================

# TODO: cleanup artifacts using geekyeggo/delete-artifact
name: Continuous Integration
permissions:
  contents: read

on:
  # Better practice is to run on any push instead of just either master push or PR.
  # Just that there is some issues with the way the CI is implemented now.
  # I.E. the module determination tstep depends on it.
  # TODO: (1) Resolve this dependency (2) remove the pull_request trigger (3) set push trigger on ** branches
  push:
    branches: master
  pull_request:
    branches: master
  merge_group:
  workflow_dispatch:
    inputs:
      ref:
        description: "The branch or tag to run the workflow on"
        required: true
        default: "master"

env:
  API_CARGO_FILE: web/api/Cargo.toml
  API_COVERAGE_ARTIFACT_NAME_MASTER: api-coverage.master
  API_COVERAGE_ARTIFACT_NAME_WF: api-coverage.${{ github.run_id }}
  API_COVERAGE_DIRECTORY: web/api/.coverage
  API_COVERAGE_REPORT: web/api/.coverage/merged/lcov.info
  API_DIRECTORY: web/api
  API_E2E_JUNIT_REPORT_ARTIFACT_NAME: api-e2e-junit-report-${{ github.run_id }}
  API_MERGED_COVERAGE_DIRECTORY: web/api/.coverage/merged
  API_TESTS_DIRECTORY: web/api/tests
  API_TESTS_NODE_CACHE_PATH: web/api/tests/package-lock.json
  API_TESTS_NODE_VERSION_FILE: web/api/tests/package.json
  API_UNIT_JUNIT_REPORT_ARTIFACT_NAME: api-unit-junit-report-${{ github.run_id }}
  APP_COVERAGE_ARTIFACT_NAME_MASTER: app-coverage.master
  APP_COVERAGE_ARTIFACT_NAME_WF: app-coverage.${{ github.run_id }}
  APP_COVERAGE_DIRECTORY: app/.coverage
  APP_COVERAGE_REPORT: app/.coverage/merged/lcov.info
  APP_MERGED_COVERAGE_DIRECTORY: app/.coverage/merged
  APP_DIRECTORY: app
  CROSS_MODULE_COVERAGE_REPORT: .coverage/lcov.info
  DATA_DIRECTORY: data
  DEVOPS_DIRECTORY: devops
  DEVOPS_NODE_CACHE_PATH: devops/package-lock.json
  DEVOPS_NODE_VERSION_FILE: devops/package.json
  IS_MASTER_BRANCH: ${{ github.ref == format('refs/heads/{0}', github.event.repository.default_branch) }}
  TMP_WEBSITE_JUNIT_REPORTS_DIRECTORY: tmp-website-junit-reports
  WEBSITE_COVERAGE_ARTIFACT_NAME_MASTER: website-coverage.master
  WEBSITE_COVERAGE_ARTIFACT_NAME_WF: website-coverage.${{ github.run_id }}
  WEBSITE_DIRECTORY: web/bible-on-site
  WEBSITE_E2E_JUNIT_REPORT_ARTIFACT_NAME: website-e2e-junit-report-${{ github.run_id }}
  WEBSITE_MERGED_COVERAGE_DIRECTORY: web/bible-on-site/.coverage/merged
  WEBSITE_MERGED_COVERAGE_REPORT: web/bible-on-site/.coverage/merged/lcov.info
  WEBSITE_NODE_CACHE_PATH: web/bible-on-site/package-lock.json
  WEBSITE_NODE_VERSION_FILE: web/bible-on-site/package.json
  WEBSITE_PERF_JUNIT_REPORT_ARTIFACT_NAME: website-perf-junit-report-${{ github.run_id }}
  WEBSITE_UNIT_JUNIT_REPORT_ARTIFACT_NAME: website-unit-junit-report-${{ github.run_id }}
  APP_UNIT_JUNIT_REPORT_ARTIFACT_NAME: app-unit-junit-report-${{ github.run_id }}
  APP_INTEGRATION_JUNIT_REPORT_ARTIFACT_NAME: app-integration-junit-report-${{ github.run_id }}
  ADMIN_DIRECTORY: web/admin
  ADMIN_NODE_CACHE_PATH: web/admin/package-lock.json
  ADMIN_NODE_VERSION_FILE: web/admin/package.json
  ADMIN_UNIT_JUNIT_REPORT_ARTIFACT_NAME: admin-unit-junit-report-${{ github.run_id }}
  ADMIN_E2E_JUNIT_REPORT_ARTIFACT_NAME: admin-e2e-junit-report-${{ github.run_id }}
  DATA_UNIT_JUNIT_REPORT_ARTIFACT_NAME: data-unit-junit-report-${{ github.run_id }}
  DATA_INTEGRATION_JUNIT_REPORT_ARTIFACT_NAME: data-integration-junit-report-${{ github.run_id }}
  LCOV_DOCKER_IMAGE_ARTIFACT_NAME: lcov-docker-image
  SEFARIA_MONGO_IMAGE_ARTIFACT_NAME: sefaria-mongo-image

jobs:
  setup_env:
    name: Setup Environment Variables
    runs-on: ubuntu-latest
    outputs:
      api_directory: ${{ env.API_DIRECTORY }} # a workaround for places where only needs.<job_id>.<output> is allowed
      api_playwright_version: ${{ steps.get_api_playwright_version.outputs.PLAYWRIGHT_VERSION }}
      app_directory: ${{ env.APP_DIRECTORY }} # a workaround for places where only needs.<job_id>.<output> is allowed
      admin_directory: ${{ env.ADMIN_DIRECTORY }} # a workaround for places where only needs.<job_id>.<output> is allowed
      data_directory: ${{ env.DATA_DIRECTORY }} # a workaround for places where only needs.<job_id>.<output> is allowed
      is_master_branch: ${{ env.IS_MASTER_BRANCH }} # a workaround for places where only needs.<job_id>.<output> is allowed
      website_directory: ${{ env.WEBSITE_DIRECTORY }} # a workaround for places where only needs.<job_id>.<output> is allowed
      website_playwright_version: ${{ steps.get_website_playwright_version.outputs.PLAYWRIGHT_VERSION }}
    steps:
      - run: echo "Setting up environment variables"
      - name: Checkout
        id: checkout
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event_name == 'workflow_dispatch' && github.event.inputs.ref || github.head_ref }}
      - name: Get API Playwright version
        id: get_api_playwright_version
        working-directory: ${{ env.API_TESTS_DIRECTORY }}
        run: echo "PLAYWRIGHT_VERSION=$(node -e "console.log(require('./package.json').devDependencies['@playwright/test'])")" >> $GITHUB_OUTPUT
      - name: Get Website Playwright version
        id: get_website_playwright_version
        working-directory: ${{ env.WEBSITE_DIRECTORY }}
        run: echo "PLAYWRIGHT_VERSION=$(node -e "console.log(require('./package.json').devDependencies['@playwright/test'])")" >> $GITHUB_OUTPUT

  determine_baseline_availability:
    name: Determine Baseline Availability
    permissions:
      contents: read
      actions: read
    runs-on: ubuntu-latest
    outputs:
      is_api_master_coverage_available: ${{ steps.check_master_coverage_artifacts.outputs.is_api_master_coverage_available }}
      is_app_master_coverage_available: ${{ steps.check_master_coverage_artifacts.outputs.is_app_master_coverage_available }}
      is_website_master_coverage_available: ${{ steps.check_master_coverage_artifacts.outputs.is_website_master_coverage_available }}
    steps:
      - name: Check and restore master coverage artifacts
        id: check_master_coverage_artifacts
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          # Function to check if artifact exists and download it
          # Downloads to make it available in current workflow run via re-upload
          # Use ?name= filter to avoid pagination issues (25k+ artifacts in repo)
          check_and_download_artifact() {
            local artifact_name=$1
            local artifact_info=$(gh api "repos/${{ github.repository }}/actions/artifacts?name=$artifact_name" \
              --jq "[.artifacts[] | select(.expired == false)] | first")

            if [ "$artifact_info" != "null" ] && [ -n "$artifact_info" ]; then
              local artifact_id=$(echo "$artifact_info" | jq -r '.id')
              echo "Found artifact $artifact_name (id: $artifact_id), downloading..." >&2
              mkdir -p "/tmp/$artifact_name"
              gh api repos/${{ github.repository }}/actions/artifacts/$artifact_id/zip > "/tmp/$artifact_name.zip"
              unzip -o "/tmp/$artifact_name.zip" -d "/tmp/$artifact_name" >&2
              echo "true"
            else
              echo "false"
            fi
          }

          IS_API_MASTER_COVERAGE_AVAILABLE=$(check_and_download_artifact "${{ env.API_COVERAGE_ARTIFACT_NAME_MASTER }}")
          IS_APP_MASTER_COVERAGE_AVAILABLE=$(check_and_download_artifact "${{ env.APP_COVERAGE_ARTIFACT_NAME_MASTER }}")
          IS_WEBSITE_MASTER_COVERAGE_AVAILABLE=$(check_and_download_artifact "${{ env.WEBSITE_COVERAGE_ARTIFACT_NAME_MASTER }}")

          echo "API master coverage available: $IS_API_MASTER_COVERAGE_AVAILABLE"
          echo "App master coverage available: $IS_APP_MASTER_COVERAGE_AVAILABLE"
          echo "Website master coverage available: $IS_WEBSITE_MASTER_COVERAGE_AVAILABLE"

          echo "is_api_master_coverage_available=$IS_API_MASTER_COVERAGE_AVAILABLE" >> $GITHUB_OUTPUT
          echo "is_app_master_coverage_available=$IS_APP_MASTER_COVERAGE_AVAILABLE" >> $GITHUB_OUTPUT
          echo "is_website_master_coverage_available=$IS_WEBSITE_MASTER_COVERAGE_AVAILABLE" >> $GITHUB_OUTPUT

      - name: Re-upload API master coverage for current workflow
        if: steps.check_master_coverage_artifacts.outputs.is_api_master_coverage_available == 'true'
        uses: actions/upload-artifact@v6
        with:
          name: ${{ env.API_COVERAGE_ARTIFACT_NAME_MASTER }}
          path: /tmp/${{ env.API_COVERAGE_ARTIFACT_NAME_MASTER }}
          retention-days: 90
          overwrite: true

      - name: Re-upload App master coverage for current workflow
        if: steps.check_master_coverage_artifacts.outputs.is_app_master_coverage_available == 'true'
        uses: actions/upload-artifact@v6
        with:
          name: ${{ env.APP_COVERAGE_ARTIFACT_NAME_MASTER }}
          path: /tmp/${{ env.APP_COVERAGE_ARTIFACT_NAME_MASTER }}
          retention-days: 90
          overwrite: true

      - name: Re-upload Website master coverage for current workflow
        if: steps.check_master_coverage_artifacts.outputs.is_website_master_coverage_available == 'true'
        uses: actions/upload-artifact@v6
        with:
          name: ${{ env.WEBSITE_COVERAGE_ARTIFACT_NAME_MASTER }}
          path: /tmp/${{ env.WEBSITE_COVERAGE_ARTIFACT_NAME_MASTER }}
          retention-days: 90
          overwrite: true

  determine_docker_image_availability:
    name: Determine Docker Image Availability
    permissions:
      contents: read
      actions: read
    runs-on: ubuntu-latest
    outputs:
      is_lcov_docker_available: ${{ steps.check_docker_images.outputs.is_lcov_docker_available }}
      is_sefaria_mongo_available: ${{ steps.check_sefaria_mongo.outputs.is_sefaria_mongo_available }}
      sefaria_mongo_artifact_id: ${{ steps.check_sefaria_mongo.outputs.sefaria_mongo_artifact_id }}
    steps:
      - name: Check and restore LCOV Docker image artifact
        id: check_docker_images
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          # Check if LCOV Docker artifact exists and download it
          # LCOV is small (~150MB) and used by 4+ jobs, so caching is worthwhile
          # Use ?name= filter to avoid pagination issues (25k+ artifacts in repo)
          artifact_name="${{ env.LCOV_DOCKER_IMAGE_ARTIFACT_NAME }}"
          artifact_info=$(gh api "repos/${{ github.repository }}/actions/artifacts?name=$artifact_name" \
            --jq "[.artifacts[] | select(.expired == false)] | first")

          if [ "$artifact_info" != "null" ] && [ -n "$artifact_info" ]; then
            artifact_id=$(echo "$artifact_info" | jq -r '.id')
            echo "Found artifact $artifact_name (id: $artifact_id), downloading..."
            mkdir -p "/tmp/$artifact_name"
            gh api repos/${{ github.repository }}/actions/artifacts/$artifact_id/zip > "/tmp/$artifact_name.zip"
            unzip -o "/tmp/$artifact_name.zip" -d "/tmp/$artifact_name"
            echo "is_lcov_docker_available=true" >> $GITHUB_OUTPUT
          else
            echo "LCOV Docker image not found in artifacts"
            echo "is_lcov_docker_available=false" >> $GITHUB_OUTPUT
          fi

      - name: Re-upload LCOV Docker image for current workflow
        if: steps.check_docker_images.outputs.is_lcov_docker_available == 'true'
        uses: actions/upload-artifact@v6
        with:
          name: ${{ env.LCOV_DOCKER_IMAGE_ARTIFACT_NAME }}
          path: /tmp/${{ env.LCOV_DOCKER_IMAGE_ARTIFACT_NAME }}
          retention-days: 400
          overwrite: true

      - name: Check Sefaria MongoDB image artifact availability
        id: check_sefaria_mongo
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          # Only check if artifact exists - don't download here
          # MongoDB image is ~5GB, only data_ci needs it, so download there directly via gh api (faster than actions/download-artifact)
          # Use ?name= filter to avoid pagination issues (25k+ artifacts in repo)
          artifact_name="${{ env.SEFARIA_MONGO_IMAGE_ARTIFACT_NAME }}"
          artifact_info=$(gh api "repos/${{ github.repository }}/actions/artifacts?name=$artifact_name" \
            --jq "[.artifacts[] | select(.expired == false)] | first")

          if [ "$artifact_info" != "null" ] && [ -n "$artifact_info" ]; then
            artifact_id=$(echo "$artifact_info" | jq -r '.id')
            echo "Found cached Sefaria MongoDB image (artifact id: $artifact_id)"
            echo "is_sefaria_mongo_available=true" >> $GITHUB_OUTPUT
            echo "sefaria_mongo_artifact_id=$artifact_id" >> $GITHUB_OUTPUT
          else
            echo "Sefaria MongoDB image not found in artifacts - will need to build"
            echo "is_sefaria_mongo_available=false" >> $GITHUB_OUTPUT
          fi

  determine_website_changes:
    name: Determine Website Changes
    needs: setup_env
    secrets: inherit
    uses: ./.github/workflows/shared-ci.yml
    with:
      module_directory: ${{ needs.setup_env.outputs.website_directory }}
      module_name: ${{ needs.setup_env.outputs.website_directory }}
      ci_path: ".github/workflows/ci.yml,.github/workflows/shared-ci.yml,.github/workflows/shared-release.yml"

  determine_api_changes:
    name: Determine API Changes
    needs: setup_env
    secrets: inherit
    uses: ./.github/workflows/shared-ci.yml
    with:
      module_directory: ${{ needs.setup_env.outputs.api_directory }}
      module_name: ${{ needs.setup_env.outputs.api_directory }}
      ci_path: ".github/workflows/ci.yml,.github/workflows/shared-ci.yml,.github/workflows/shared-release.yml"

  determine_app_changes:
    name: Determine App Changes
    needs: setup_env
    secrets: inherit
    uses: ./.github/workflows/shared-ci.yml
    with:
      module_directory: ${{ needs.setup_env.outputs.app_directory }}
      module_name: ${{ needs.setup_env.outputs.app_directory }}
      ci_path: ".github/workflows/ci.yml,.github/workflows/shared-ci.yml,.github/workflows/shared-release.yml"

  determine_admin_changes:
    name: Determine Admin Changes
    needs: setup_env
    secrets: inherit
    uses: ./.github/workflows/shared-ci.yml
    with:
      module_directory: ${{ needs.setup_env.outputs.admin_directory }}
      module_name: ${{ needs.setup_env.outputs.admin_directory }}
      ci_path: ".github/workflows/ci.yml,.github/workflows/shared-ci.yml"

  determine_data_changes:
    name: Determine Data Changes
    needs: setup_env
    secrets: inherit
    uses: ./.github/workflows/shared-ci.yml
    with:
      module_directory: ${{ needs.setup_env.outputs.data_directory }}
      module_name: ${{ needs.setup_env.outputs.data_directory }}
      ci_path: ".github/workflows/ci.yml,.github/workflows/shared-ci.yml"

  # Version Verification Jobs
  # These jobs run on PRs and master to verify that module versions are properly bumped
  # before any release can occur. This prevents CD failures due to duplicate versions.
  verify_website_version:
    name: Verify Website Version
    needs: [setup_env, determine_website_changes]
    if: ${{ needs.determine_website_changes.outputs.module_changed == 'true' }}
    uses: ./.github/workflows/shared-verify-version.yml
    with:
      module_name: website
      ref: ${{ github.head_ref || github.ref }}

  verify_api_version:
    name: Verify API Version
    needs: [setup_env, determine_api_changes]
    if: ${{ needs.determine_api_changes.outputs.module_changed == 'true' }}
    uses: ./.github/workflows/shared-verify-version.yml
    with:
      module_name: api
      ref: ${{ github.head_ref || github.ref }}

  verify_app_version:
    name: Verify App Version
    needs: [setup_env, determine_app_changes]
    if: ${{ needs.determine_app_changes.outputs.module_changed == 'true' }}
    uses: ./.github/workflows/shared-verify-version.yml
    with:
      module_name: app
      ref: ${{ github.head_ref || github.ref }}

  package_website:
    name: Package Website
    needs: [setup_env, determine_website_changes]
    if: ${{ needs.determine_website_changes.outputs.module_changed == 'true' && needs.setup_env.outputs.is_master_branch == 'true' && github.event_name == 'push' }}
    permissions:
      contents: write
      actions: read
      id-token: write # Required for AWS OIDC authentication to access RDS during SSG build
    secrets: inherit
    uses: ./.github/workflows/shared-dockerize.yml
    with:
      module_directory: ${{ needs.setup_env.outputs.website_directory }}

  package_api:
    name: Package API
    needs: [setup_env, determine_api_changes]
    if: ${{ needs.determine_api_changes.outputs.module_changed == 'true' && needs.setup_env.outputs.is_master_branch == 'true' && github.event_name == 'push' }}
    permissions:
      contents: write
      actions: read
      id-token: write # Required by shared-dockerize.yml
    secrets: inherit
    uses: ./.github/workflows/shared-dockerize.yml
    with:
      module_directory: ${{ needs.setup_env.outputs.api_directory }}

  package_app:
    name: Package App
    needs: [setup_env, determine_app_changes]
    if: ${{ needs.determine_app_changes.outputs.module_changed == 'true' && needs.setup_env.outputs.is_master_branch == 'true' && github.event_name == 'push' }}
    permissions:
      contents: read
      actions: read
    secrets: inherit
    uses: ./.github/workflows/app-package.yml
    with:
      platform: All

  build_lcov_docker:
    name: Build LCOV Docker Image
    needs: [setup_env, determine_docker_image_availability]
    if: ${{ needs.determine_docker_image_availability.outputs.is_lcov_docker_available != 'true' }}
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event_name == 'workflow_dispatch' && github.event.inputs.ref || github.head_ref }}

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
        with:
          driver-opts: |
            network=host
            image=moby/buildkit:v0.22.0

      - name: Build And Cache lcov Docker Image
        uses: docker/build-push-action@v6
        with:
          context: devops/coverage/lcov-docker/
          file: devops/coverage/lcov-docker/Dockerfile
          tags: lcov-cli:0.0.2
          outputs: type=docker,dest=/tmp/lcov-docker-image.tar
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Store Docker Image
        uses: actions/upload-artifact@v6
        with:
          name: ${{ env.LCOV_DOCKER_IMAGE_ARTIFACT_NAME }}
          path: /tmp/lcov-docker-image.tar
          retention-days: 400

  build_sefaria_mongo_docker:
    name: Build Sefaria MongoDB Docker Image
    needs: [setup_env, determine_data_changes, determine_docker_image_availability]
    if: ${{ needs.determine_docker_image_availability.outputs.is_sefaria_mongo_available != 'true' && (needs.determine_data_changes.outputs.module_changed == 'true' || needs.determine_data_changes.outputs.ci_changed == 'true') }}
    runs-on: ubuntu-latest
    steps:
      # Free disk space for the MongoDB Docker image build (~10GB+ needed for mongorestore)
      # Enable large-packages and docker-images to maximize available space
      - name: Free Disk Space
        uses: jlumbroso/free-disk-space@v1.3.1
        with:
          tool-cache: false
          android: true
          dotnet: true
          haskell: true
          large-packages: true
          docker-images: true
          swap-storage: true

      - name: Checkout
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event_name == 'workflow_dispatch' && github.event.inputs.ref || github.head_ref }}

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
        with:
          driver-opts: |
            network=host
            image=moby/buildkit:v0.22.0

      - name: Build And Cache Sefaria MongoDB Docker Image
        uses: docker/build-push-action@v6
        with:
          context: data/sefaria/mongodb-docker/
          file: data/sefaria/mongodb-docker/Dockerfile
          tags: sefaria-mongo:latest
          outputs: type=docker,dest=/tmp/sefaria-mongo-image.tar
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Store Docker Image
        uses: actions/upload-artifact@v6
        with:
          name: ${{ env.SEFARIA_MONGO_IMAGE_ARTIFACT_NAME }}
          path: /tmp/sefaria-mongo-image.tar
          retention-days: 90

  # ACTUAL JOBS
  website_performance:
    name: Website Performance
    runs-on: ubuntu-latest
    needs: [setup_env, determine_website_changes]
    if: ${{ needs.determine_website_changes.outputs.module_changed == 'true' || needs.determine_website_changes.outputs.ci_changed == 'true' }}
    defaults:
      run:
        working-directory: ${{ env.WEBSITE_DIRECTORY }}
    permissions:
      checks: write # Required by Bencher to create GitHub Check on push to master
      pull-requests: write # Required by Bencher to add comment on PRs

    steps:
      - name: Checkout
        id: checkout
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event_name == 'workflow_dispatch' && github.event.inputs.ref || github.head_ref }}

      - name: Setup Node.js
        id: setup-node
        uses: actions/setup-node@v6
        with:
          node-version-file: ${{ env.WEBSITE_NODE_VERSION_FILE }}
          cache-dependency-path: ${{ env.WEBSITE_NODE_CACHE_PATH }}
          cache: npm

      - name: Cache playwright binaries
        uses: actions/cache@v5
        id: playwright-cache
        with:
          path: |
            ~/.cache/ms-playwright
          key: ${{ runner.os }}-playwright-${{ needs.setup_env.outputs.website_playwright_version }}

      - name: Install npm Dependencies
        id: npm_ci
        run: |
          npm ci --no-audit

      - name: Install Playwright Dependencies
        if: steps.playwright-cache.outputs.cache-hit != 'true'
        run: |
          npx playwright install --with-deps
          npx playwright install-deps

      - name: Build cache
        uses: actions/cache@v5
        with:
          path: ${{ env.WEBSITE_DIRECTORY }}/.next/cache
          key: ${{ runner.os }}-nextjs-${{ hashFiles(format('{0}/package-lock.json', env.WEBSITE_DIRECTORY)) }}-${{ hashFiles(format('{0}/**/*.js', env.WEBSITE_DIRECTORY), format('{0}/**/*.jsx', env.WEBSITE_DIRECTORY), format('{0}/**/*.ts', env.WEBSITE_DIRECTORY), format('{0}/**/*.tsx', env.WEBSITE_DIRECTORY)) }}
          # If source files changed but packages didn't, rebuild from a prior cache.
          restore-keys: |
            ${{ runner.os }}-nextjs-${{ hashFiles(format('{0}/package-lock.json', env.WEBSITE_DIRECTORY)) }}-

      - name: Build
        id: npm-build
        run: npm run build

      - name: Perf Test
        id: npm-perf-test
        run: npm run test:perf

      - name: Install Bencher CLI
        uses: bencherdev/bencher@main

      - name: Track Performance with Bencher
        env:
          BENCHER_PROJECT: bible-on-site-website
          BENCHER_BRANCH: ${{ github.head_ref || github.ref_name }} # PR source branch, or branch name on push
        run: |
          bencher run \
            --project "$BENCHER_PROJECT" \
            --token "${{ secrets.BENCHER_API_TOKEN }}" \
            --branch "$BENCHER_BRANCH" \
            --testbed ubuntu-latest \
            --adapter json \
            --github-actions '${{ secrets.GITHUB_TOKEN }}' \
            --file .playwright-report/perf/bencher/benchmark.json \
            --threshold-measure time_ms --threshold-test percentage --threshold-max-sample-size 64 --threshold-upper-boundary 5.00 --threshold-lower-boundary _ \
            --threshold-measure memory_mb --threshold-test percentage --threshold-max-sample-size 64 --threshold-upper-boundary 5.00 --threshold-lower-boundary _ \
            --threshold-measure size_mb --threshold-test percentage --threshold-max-sample-size 64 --threshold-upper-boundary 5.00 --threshold-lower-boundary _ \
            --threshold-measure score --threshold-test percentage --threshold-max-sample-size 64 --threshold-upper-boundary _ --threshold-lower-boundary 5.00 \
            --threshold-measure ratio --threshold-test percentage --threshold-max-sample-size 64 --threshold-upper-boundary 20.00 --threshold-lower-boundary _ \
            --threshold-measure bytes --threshold-test percentage --threshold-max-sample-size 64 --threshold-upper-boundary 5.00 --threshold-lower-boundary _ \
            --threshold-measure count --threshold-test percentage --threshold-max-sample-size 64 --threshold-upper-boundary 10.00 --threshold-lower-boundary _ \

      - name: Store Website Perf HTML Report
        uses: actions/upload-artifact@v6
        with:
          name: website-perf-html-report-${{ github.run_id }}
          path: ${{ env.WEBSITE_DIRECTORY }}/.playwright-report/perf/html
          retention-days: 7
          overwrite: true

      - name: Store Website Perf JUnit Report
        uses: actions/upload-artifact@v6
        with:
          name: ${{ env.WEBSITE_PERF_JUNIT_REPORT_ARTIFACT_NAME }}
          path: ${{ env.WEBSITE_DIRECTORY }}/.playwright-report/perf/junit/perf-results.xml
          retention-days: 1
          overwrite: true

  website_e2e:
    name: Website CI
    runs-on: ubuntu-latest
    needs:
      [
        setup_env,
        determine_website_changes,
        determine_baseline_availability,
        determine_docker_image_availability,
        build_lcov_docker,
      ]
    if: ${{ always() && !cancelled() && !failure() && (needs.determine_website_changes.outputs.module_changed == 'true' || needs.determine_website_changes.outputs.ci_changed == 'true' || needs.determine_baseline_availability.outputs.is_website_master_coverage_available == 'false') }}
    defaults:
      run:
        working-directory: ${{ env.WEBSITE_DIRECTORY }}
    permissions:
      contents: read

    steps:
      - name: Checkout
        id: checkout
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event_name == 'workflow_dispatch' && github.event.inputs.ref || github.head_ref }}

      - name: Setup Node.js
        id: setup-node
        uses: actions/setup-node@v6
        with:
          node-version-file: ${{ env.WEBSITE_NODE_VERSION_FILE }}
          cache-dependency-path: ${{ env.WEBSITE_NODE_CACHE_PATH }}
          cache: npm

      - name: Cache playwright binaries
        uses: actions/cache@v5
        id: playwright-cache
        with:
          path: |
            ~/.cache/ms-playwright
          key: ${{ runner.os }}-playwright-${{ needs.setup_env.outputs.website_playwright_version }}

      - name: Install npm Dependencies
        id: npm_ci
        run: |
          npm ci --no-audit

      - name: Install Playwright Dependencies
        if: steps.playwright-cache.outputs.cache-hit != 'true'
        run: |
          npx playwright install --with-deps
          npx playwright install-deps

      - name: Lint
        id: npm-lint
        run: npm run lint

      - name: Unit Test
        id: npm-unit-test
        run: npm run coverage:unit

      - name: Store Website Unit JUnit Report
        uses: actions/upload-artifact@v6
        with:
          name: ${{ env.WEBSITE_UNIT_JUNIT_REPORT_ARTIFACT_NAME }}
          path: ${{ env.WEBSITE_DIRECTORY }}/.jest-report/unit-results.xml
          retention-days: 1
          overwrite: true

      - name: Build cache
        uses: actions/cache@v5
        with:
          path: ${{ env.WEBSITE_DIRECTORY }}/.next/cache
          key: ${{ runner.os }}-nextjs-${{ hashFiles(format('{0}/package-lock.json', env.WEBSITE_DIRECTORY)) }}-${{ hashFiles(format('{0}/**/*.js', env.WEBSITE_DIRECTORY), format('{0}/**/*.jsx', env.WEBSITE_DIRECTORY), format('{0}/**/*.ts', env.WEBSITE_DIRECTORY), format('{0}/**/*.tsx', env.WEBSITE_DIRECTORY)) }}
          # If source files changed but packages didn't, rebuild from a prior cache.
          restore-keys: |
            ${{ runner.os }}-nextjs-${{ hashFiles(format('{0}/package-lock.json', env.WEBSITE_DIRECTORY)) }}-

      # ============ MySQL Setup for Articles ============
      - name: Install and start MySQL
        id: mysql
        uses: shogo82148/actions-setup-mysql@v1
        with:
          mysql-version: "8.4"
          root-password: test_123
          distribution: "mysql"
          auto-start: true

      - name: Setup Rust
        uses: dtolnay/rust-toolchain@stable

      - name: Install cargo-make
        uses: taiki-e/install-action@v2
        with:
          tool: cargo-make

      - name: Cache Cargo dependencies
        uses: Swatinem/rust-cache@v2
        with:
          workspaces: ${{ env.DATA_DIRECTORY }}

      # Pre-build the data crate to warm the cache before E2E tests
      # This prevents timeout when launcher runs cargo make mysql-populate
      - name: Pre-build data crate for E2E tests
        working-directory: ${{ env.DATA_DIRECTORY }}
        run: cargo build --release

      - name: Build
        id: npm-build
        run: npm run build

      - name: E2E Test
        id: npm-e2e-test
        env:
          DB_URL: mysql://root:test_123@127.0.0.1:3306/tanah_test
        run: npm run coverage:e2e

      - name: Store Website E2E HTML Report
        uses: actions/upload-artifact@v6
        with:
          name: website-e2e-html-report-${{ github.run_id }}
          path: ${{ env.WEBSITE_DIRECTORY }}/.playwright-report/e2e/html
          retention-days: 7
          overwrite: true

      - name: Store Website E2E JUnit Report
        uses: actions/upload-artifact@v6
        with:
          name: ${{ env.WEBSITE_E2E_JUNIT_REPORT_ARTIFACT_NAME }}
          path: ${{ env.WEBSITE_DIRECTORY }}/.playwright-report/e2e/junit/e2e-results.xml
          retention-days: 1
          overwrite: true

      - name: Restore lcov Docker image
        uses: actions/download-artifact@v7
        with:
          name: ${{ env.LCOV_DOCKER_IMAGE_ARTIFACT_NAME }}
          path: /tmp

      - name: Load lcov Docker image
        run: docker load --input /tmp/lcov-docker-image.tar

      - name: Merge Test Coverage (Unit + E2E)
        continue-on-error: true
        run: npm run coverage:merge

      - name: Log merged coverage summary
        if: always()
        run: |
          if [ -f "${{ env.WEBSITE_MERGED_COVERAGE_REPORT }}" ]; then
            docker run --rm -v ${{ github.workspace }}/${{ env.WEBSITE_DIRECTORY }}/.coverage:/.coverage lcov-cli:0.0.2 --summary /.coverage/merged/lcov.info || true
          else
            echo "Merged coverage file not found (merge may have failed)"
          fi

      - name: Store Coverage Debug Snippets
        if: always()
        uses: actions/upload-artifact@v6
        with:
          name: website-coverage-debug-${{ github.run_id }}
          path: ${{ env.WEBSITE_DIRECTORY }}/.coverage/debug
          retention-days: 7
          overwrite: true

      - name: Store Website Coverage Report (wf)
        uses: actions/upload-artifact@v6
        with:
          name: ${{ env.WEBSITE_COVERAGE_ARTIFACT_NAME_WF }}
          path: ${{ env.WEBSITE_MERGED_COVERAGE_REPORT }}
          retention-days: 400
          overwrite: true
          if-no-files-found: error

      - name: Store Website Coverage Report (master)
        if: ${{ env.IS_MASTER_BRANCH == 'true' }}
        uses: actions/upload-artifact@v6
        with:
          name: ${{ env.WEBSITE_COVERAGE_ARTIFACT_NAME_MASTER }}
          path: ${{ env.WEBSITE_MERGED_COVERAGE_REPORT }}
          retention-days: 400
          overwrite: true

  admin_ci:
    name: Admin CI
    runs-on: ubuntu-latest
    needs: [setup_env, determine_admin_changes]
    if: ${{ needs.determine_admin_changes.outputs.module_changed == 'true' || needs.determine_admin_changes.outputs.ci_changed == 'true' }}
    defaults:
      run:
        working-directory: ${{ env.ADMIN_DIRECTORY }}
    permissions:
      contents: read

    steps:
      - name: Checkout
        id: checkout
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event_name == 'workflow_dispatch' && github.event.inputs.ref || github.head_ref }}

      - name: Setup Node.js
        id: setup-node
        uses: actions/setup-node@v6
        with:
          node-version-file: ${{ env.ADMIN_NODE_VERSION_FILE }}
          cache-dependency-path: ${{ env.ADMIN_NODE_CACHE_PATH }}
          cache: npm

      - name: Install npm Dependencies
        id: npm_ci
        run: npm ci --no-audit

      - name: Install Playwright Browsers
        run: npx playwright install --with-deps chromium

      - name: Lint
        id: npm-lint
        run: npm run lint

      - name: Type Check
        id: npm-typecheck
        run: npx tsc --noEmit

      - name: Unit Test
        id: npm-unit-test
        run: npm run test:unit

      - name: Build
        id: npm-build
        run: npm run build

      - name: Store Admin Unit JUnit Report
        uses: actions/upload-artifact@v6
        with:
          name: ${{ env.ADMIN_UNIT_JUNIT_REPORT_ARTIFACT_NAME }}
          path: ${{ env.ADMIN_DIRECTORY }}/.junit-report/unit-results.xml
          retention-days: 1
          overwrite: true
          if-no-files-found: ignore

      # ============ MySQL and MinIO Setup for E2E Tests ============
      - name: Install and start MySQL
        id: mysql
        uses: shogo82148/actions-setup-mysql@v1
        with:
          mysql-version: "8.4"
          root-password: test_123
          distribution: "mysql"
          auto-start: true

      - name: Start MinIO
        run: |
          docker run -d --name minio \
            -p 4566:9000 \
            -e MINIO_ROOT_USER=test \
            -e MINIO_ROOT_PASSWORD=test_1234 \
            minio/minio:latest server /data
          # Wait for MinIO to be ready
          for i in $(seq 1 30); do
            if curl -sf http://localhost:4566/minio/health/live; then break; fi
            sleep 1
          done

      - name: Create S3 bucket in MinIO
        run: |
          docker run --rm --network host \
            --entrypoint /bin/sh \
            minio/mc:latest \
            -c "
              mc alias set ci http://localhost:4566 test test_1234 &&
              mc mb --ignore-existing ci/bible-on-site-assets-test &&
              mc anonymous set download ci/bible-on-site-assets-test
            "

      - name: Setup Rust
        uses: dtolnay/rust-toolchain@stable

      - name: Install cargo-make
        uses: taiki-e/install-action@v2
        with:
          tool: cargo-make

      - name: Cache Cargo dependencies
        uses: Swatinem/rust-cache@v2
        with:
          workspaces: ${{ env.DATA_DIRECTORY }}

      # Pre-build the data crates to warm the cache before E2E tests
      # This prevents timeout when the E2E launcher runs cargo make mysql-populate and s3-populate-test
      - name: Pre-build data crates for E2E tests
        working-directory: ${{ env.DATA_DIRECTORY }}
        run: cargo build --release --workspace

      - name: E2E Test
        id: npm-e2e-test
        env:
          DB_URL: mysql://root:test_123@127.0.0.1:3306/tanah_test
          S3_ENDPOINT: http://localhost:4566
          S3_BUCKET: bible-on-site-assets-test
          S3_REGION: us-east-1
          S3_ACCESS_KEY_ID: test
          S3_SECRET_ACCESS_KEY: test_1234
          S3_FORCE_PATH_STYLE: "true"
        run: npm run test:e2e

      - name: Store Admin E2E HTML Report
        uses: actions/upload-artifact@v6
        if: always()
        with:
          name: admin-e2e-html-report-${{ github.run_id }}
          path: ${{ env.ADMIN_DIRECTORY }}/.playwright-report
          retention-days: 7
          overwrite: true

  api_e2e:
    name: API CI
    runs-on: ubuntu-latest
    needs:
      [
        setup_env,
        determine_api_changes,
        determine_baseline_availability,
        determine_docker_image_availability,
        build_lcov_docker,
      ]
    if: ${{ always() && !cancelled() && !failure() && (needs.determine_api_changes.outputs.module_changed == 'true' || needs.determine_api_changes.outputs.ci_changed == 'true' || needs.determine_baseline_availability.outputs.is_api_master_coverage_available == 'false') }}
    permissions:
      contents: read

    steps:
      - name: Checkout
        id: checkout
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event_name == 'workflow_dispatch' && github.event.inputs.ref || github.head_ref }}

      - name: Setup Rust
        uses: dtolnay/rust-toolchain@stable
        with:
          components: clippy

      - uses: taiki-e/install-action@v2
        with:
          tool: cargo-make, cargo-llvm-cov, cargo-nextest

      - name: Cache Cargo dependencies
        uses: Swatinem/rust-cache@v2
        with:
          workspaces: |
            ${{ env.API_DIRECTORY }}
            ${{ env.DATA_DIRECTORY }}

      - name: Lint
        id: lint
        working-directory: ${{ env.API_DIRECTORY }}
        run: cargo make lint

      - name: Unit Test
        id: unit-test
        working-directory: ${{ env.API_DIRECTORY }}
        run: cargo make coverage-unit

      - name: Setup DevOps Node.js
        id: setup-devops-node
        uses: actions/setup-node@v6
        with:
          node-version-file: ${{ env.DEVOPS_NODE_VERSION_FILE }}
          cache-dependency-path: ${{ env.DEVOPS_NODE_CACHE_PATH }}
          cache: npm

      - name: Install devops npm Dependencies
        id: devops_npm_ci
        working-directory: ${{ env.DEVOPS_DIRECTORY }}
        run: |
          npm ci --no-audit

      - name: Install and start MySQL
        id: mysql
        uses: shogo82148/actions-setup-mysql@v1
        with:
          mysql-version: "8.4"
          root-password: test_123
          distribution: "mysql"
          auto-start: true

      - name: Setup Tests Node.js
        id: setup-tests-node
        uses: actions/setup-node@v6
        with:
          node-version-file: ${{ env.API_TESTS_NODE_VERSION_FILE }}
          cache-dependency-path: ${{ env.API_TESTS_NODE_CACHE_PATH }}
          cache: npm

      - name: Cache playwright binaries
        uses: actions/cache@v5
        id: playwright-cache
        with:
          path: |
            ~/.cache/ms-playwright
          key: ${{ runner.os }}-playwright-${{ needs.setup_env.outputs.api_playwright_version }}

      - name: Install Tests npm Dependencies
        id: tests_npm_ci
        working-directory: ${{ env.API_TESTS_DIRECTORY }}
        run: |
          npm ci --no-audit

      - name: Install Playwright Dependencies
        if: steps.playwright-cache.outputs.cache-hit != 'true'
        working-directory: ${{ env.API_TESTS_DIRECTORY }}
        run: |
          npx playwright install --with-deps
          npx playwright install-deps

      - name: E2E Test
        id: api-e2e
        working-directory: ${{ env.API_DIRECTORY }}
        env:
          DB_URL: mysql://root:test_123@127.0.0.1:3306/tanah_test
        run: |
          cargo make coverage-e2e

      - name: Show E2E Debug Logs
        if: ${{ always() }}
        working-directory: ${{ env.API_DIRECTORY }}
        run: |
          echo "=== API E2E Debug Logs ==="
          echo "--- Global Setup Log ---"
          cat tests/.log/global-setup.log 2>/dev/null || echo "(no global-setup.log)"
          echo "--- API Server Log ---"
          cat tests/.log/api.log 2>/dev/null || echo "(no api.log)"
          echo "--- API Launcher Log ---"
          cat tests/.log/api_launcher.log 2>/dev/null || echo "(no api_launcher.log)"
          echo "========================="

      - name: Restore lcov Docker image
        uses: actions/download-artifact@v7
        with:
          name: ${{ env.LCOV_DOCKER_IMAGE_ARTIFACT_NAME }}
          path: /tmp

      - name: Load lcov Docker image
        run: docker load --input /tmp/lcov-docker-image.tar

      - name: Merge Test Coverage (Unit + E2E)
        working-directory: ${{ env.API_DIRECTORY }}
        run: cargo make coverage-merge

      - name: Store API Unit JUnit Report
        uses: actions/upload-artifact@v6
        with:
          name: ${{ env.API_UNIT_JUNIT_REPORT_ARTIFACT_NAME }}
          path: ${{ env.API_DIRECTORY }}/.junit-report/unit/results.xml
          retention-days: 1
          overwrite: true

      - name: Store API E2E JUnit Report
        uses: actions/upload-artifact@v6
        with:
          name: ${{ env.API_E2E_JUNIT_REPORT_ARTIFACT_NAME }}
          path: ${{ env.API_DIRECTORY }}/.playwright-report/e2e/junit/results.xml
          retention-days: 1
          overwrite: true

      - name: List API JUnit files
        id: list_api_junit_files
        run: |
          files="${{ env.API_DIRECTORY }}/.junit-report/unit/results.xml,${{ env.API_DIRECTORY }}/.playwright-report/e2e/junit/results.xml"
          echo "junit_files=$files" >> $GITHUB_OUTPUT

      - name: Publish API Unit/E2E Report To Codecov
        if: ${{ !cancelled() }}
        uses: codecov/codecov-action@v5
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          files: ${{ steps.list_api_junit_files.outputs.junit_files }}
          flags: api
          report_type: test_results

      - name: Store API E2E HTML Report
        uses: actions/upload-artifact@v6
        with:
          name: api-e2e-html-report-${{ github.run_id }}
          path: ${{ env.API_DIRECTORY }}/.playwright-report/e2e/html
          retention-days: 7
          overwrite: true

      - name: Store API Coverage Report (wf)
        uses: actions/upload-artifact@v6
        with:
          name: ${{ env.API_COVERAGE_ARTIFACT_NAME_WF }}
          path: ${{ env.API_COVERAGE_REPORT }}
          retention-days: 400
          overwrite: true

      - name: Store API Coverage Report (master)
        if: ${{ env.IS_MASTER_BRANCH == 'true' }}
        uses: actions/upload-artifact@v6
        with:
          name: ${{ env.API_COVERAGE_ARTIFACT_NAME_MASTER }}
          path: ${{ env.API_COVERAGE_REPORT }}
          retention-days: 400
          overwrite: true

  app_ci:
    name: App CI
    runs-on: ubuntu-latest
    needs:
      [
        setup_env,
        determine_app_changes,
        determine_baseline_availability,
        determine_docker_image_availability,
        build_lcov_docker,
      ]
    if: ${{ always() && !cancelled() && !failure() && (needs.determine_app_changes.outputs.module_changed == 'true' || needs.determine_app_changes.outputs.ci_changed == 'true' || needs.determine_baseline_availability.outputs.is_app_master_coverage_available == 'false') }}
    defaults:
      run:
        working-directory: ${{ env.APP_DIRECTORY }}
    permissions:
      contents: read

    steps:
      - name: Checkout
        id: checkout
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event_name == 'workflow_dispatch' && github.event.inputs.ref || github.head_ref }}

      - name: Setup .NET
        uses: actions/setup-dotnet@v5
        with:
          dotnet-version: "9.0.x"

      - name: Cache NuGet packages
        uses: actions/cache@v5
        with:
          path: ~/.nuget/packages
          key: ${{ runner.os }}-nuget-${{ hashFiles('**/BibleOnSite.Tests.csproj') }}
          restore-keys: |
            ${{ runner.os }}-nuget-

      - name: Restore dotnet tools
        run: dotnet tool restore

      - name: Run Unit Tests with Coverage
        run: dotnet run --project devops -- CoverageUnit --configuration Release

      - name: Store App Unit JUnit Report
        uses: actions/upload-artifact@v6
        with:
          name: ${{ env.APP_UNIT_JUNIT_REPORT_ARTIFACT_NAME }}
          path: ${{ env.APP_DIRECTORY }}/BibleOnSite.Tests/TestResults/test-results.xml
          retention-days: 1
          overwrite: true

      - name: Publish App Unit Report To Codecov
        if: ${{ !cancelled() }}
        uses: codecov/codecov-action@v5
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          files: ${{ env.APP_DIRECTORY }}/BibleOnSite.Tests/TestResults/test-results.xml
          flags: app
          report_type: test_results

      # ============ Integration Tests Setup ============
      - name: Setup Rust
        uses: dtolnay/rust-toolchain@stable

      - uses: taiki-e/install-action@v2
        with:
          tool: cargo-make

      - name: Cache Cargo dependencies
        uses: Swatinem/rust-cache@v2
        with:
          workspaces: |
            ${{ env.API_DIRECTORY }}
            ${{ env.DATA_DIRECTORY }}

      - name: Install and start MySQL
        id: mysql
        uses: shogo82148/actions-setup-mysql@v1
        with:
          mysql-version: "8.4"
          root-password: test_123
          distribution: "mysql"
          auto-start: true

      - name: Run Integration Tests with Coverage
        env:
          DB_URL: mysql://root:test_123@127.0.0.1:3306/tanah_test
          API_URL: http://127.0.0.1:3003
        run: dotnet run --project devops -- CoverageIntegration --configuration Release

      - name: Store App Integration JUnit Report
        uses: actions/upload-artifact@v6
        with:
          name: ${{ env.APP_INTEGRATION_JUNIT_REPORT_ARTIFACT_NAME }}
          path: ${{ env.APP_DIRECTORY }}/BibleOnSite.Tests/TestResults/test-results.xml
          retention-days: 1
          overwrite: true

      - name: Publish App Integration Report To Codecov
        if: ${{ !cancelled() }}
        uses: codecov/codecov-action@v5
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          files: ${{ env.APP_DIRECTORY }}/BibleOnSite.Tests/TestResults/test-results.xml
          flags: app
          report_type: test_results

      # ============ Coverage Merge ============
      - name: Restore lcov Docker image
        uses: actions/download-artifact@v7
        with:
          name: ${{ env.LCOV_DOCKER_IMAGE_ARTIFACT_NAME }}
          path: /tmp

      - name: Load lcov Docker image
        run: docker load --input /tmp/lcov-docker-image.tar

      - name: Merge Coverage Reports
        run: dotnet run --project devops -- CoverageMerge --configuration Release

      - name: Store App Coverage Report (wf)
        uses: actions/upload-artifact@v6
        with:
          name: ${{ env.APP_COVERAGE_ARTIFACT_NAME_WF }}
          path: ${{ env.APP_COVERAGE_REPORT }}
          retention-days: 400
          overwrite: true
          if-no-files-found: error

      - name: Store App Coverage Report (master)
        if: ${{ env.IS_MASTER_BRANCH == 'true' }}
        uses: actions/upload-artifact@v6
        with:
          name: ${{ env.APP_COVERAGE_ARTIFACT_NAME_MASTER }}
          path: ${{ env.APP_COVERAGE_REPORT }}
          retention-days: 400
          overwrite: true

  data_ci:
    name: Data CI
    runs-on: ubuntu-latest
    needs: [setup_env, determine_data_changes, determine_docker_image_availability, build_sefaria_mongo_docker]
    if: ${{ always() && !cancelled() && !failure() && (needs.determine_data_changes.outputs.module_changed == 'true' || needs.determine_data_changes.outputs.ci_changed == 'true') }}
    defaults:
      run:
        working-directory: ${{ env.DATA_DIRECTORY }}
    permissions:
      contents: read

    steps:
      - name: Checkout
        id: checkout
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event_name == 'workflow_dispatch' && github.event.inputs.ref || github.head_ref }}

      # Free disk space EARLY - before Rust cache restore which can consume several GB
      # This ensures enough space for the ~5GB MongoDB Docker image later
      # Note: swap-storage must be true to match build_sefaria_mongo_docker job settings
      - name: Free Disk Space
        uses: jlumbroso/free-disk-space@v1.3.1
        with:
          tool-cache: false
          android: true
          dotnet: true
          haskell: true
          large-packages: true
          docker-images: true
          swap-storage: true

      - name: Setup Rust
        uses: dtolnay/rust-toolchain@stable
        with:
          components: clippy

      - uses: taiki-e/install-action@v2
        with:
          tool: cargo-make, cargo-nextest

      - name: Cache Cargo dependencies
        uses: Swatinem/rust-cache@v2
        with:
          workspaces: ${{ env.DATA_DIRECTORY }}
          cache-on-failure: true
          shared-key: "data-rust"

      - name: Lint
        id: lint
        run: cargo make lint

      - name: Format Check
        id: fmt-check
        run: cargo make fmt-check

      - name: Unit Test
        id: unit-test
        run: cargo make test-unit-junit

      - name: Store Data Unit JUnit Report
        uses: actions/upload-artifact@v6
        with:
          name: ${{ env.DATA_UNIT_JUNIT_REPORT_ARTIFACT_NAME }}
          path: ${{ env.DATA_DIRECTORY }}/.junit-report/unit/results.xml
          retention-days: 1
          overwrite: true

      - name: Publish Data Unit Report To Codecov
        if: ${{ !cancelled() }}
        uses: codecov/codecov-action@v5
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          files: ${{ env.DATA_DIRECTORY }}/.junit-report/unit/results.xml
          flags: data
          report_type: test_results

      # Download using gh api (faster than actions/download-artifact: ~2m vs ~6m)
      - name: Download Sefaria MongoDB Docker Image
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          artifact_id="${{ needs.determine_docker_image_availability.outputs.sefaria_mongo_artifact_id }}"
          if [ -n "$artifact_id" ] && [ "$artifact_id" != "" ]; then
            echo "Downloading cached artifact (id: $artifact_id) via gh api..."
            gh api repos/${{ github.repository }}/actions/artifacts/$artifact_id/zip > /tmp/sefaria-mongo-image.zip
            unzip -o /tmp/sefaria-mongo-image.zip -d /tmp
            # Remove zip to free ~5GB before docker load needs to extract layers
            rm -f /tmp/sefaria-mongo-image.zip
          else
            echo "No cached artifact, downloading from current workflow..."
            gh run download ${{ github.run_id }} -n ${{ env.SEFARIA_MONGO_IMAGE_ARTIFACT_NAME }} -D /tmp
          fi
          echo "Disk space before docker load:"
          df -h /

      # ============ Integration Test Setup: MongoDB Container ============
      - name: Load Sefaria MongoDB Docker Image
        run: |
          docker load --input /tmp/sefaria-mongo-image.tar
          # Remove tar to free space after loading
          rm -f /tmp/sefaria-mongo-image.tar

      - name: Setup MongoDB Container for Integration Tests
        id: setup-mongodb
        run: |
          docker run -d --name sefaria-mongo -p 27017:27017 sefaria-mongo:latest
          echo "Waiting for MongoDB to be ready..."
          # Data was restored at Docker BUILD time to /mongodb-data
          # On first container startup, entrypoint.sh copies it to /data/db
          # This should take ~15-30 seconds vs 5+ minutes for runtime mongorestore
          for i in {1..60}; do
            count=$(docker exec sefaria-mongo mongosh --quiet --eval "db.getSiblingDB('sefaria').texts.countDocuments({})" 2>/dev/null || echo "0")
            if [ "$count" != "0" ] && [ -n "$count" ]; then
              echo "MongoDB is ready with $count documents in sefaria.texts collection!"
              exit 0
            fi
            echo "Attempt $i/60: Waiting for MongoDB (count: $count)..."
            sleep 2
          done
          echo "MongoDB failed to be ready within timeout"
          docker logs sefaria-mongo
          exit 1

      # ============ Integration Tests ============
      - name: Integration Test
        id: integration-test
        env:
          MONGO_HOST: localhost
          MONGO_PORT: 27017
          DUMP_NAME: sefaria
        run: cargo make test-integration-junit

      - name: Store Data Integration JUnit Report
        if: ${{ !cancelled() }}
        uses: actions/upload-artifact@v6
        with:
          name: ${{ env.DATA_INTEGRATION_JUNIT_REPORT_ARTIFACT_NAME }}
          path: ${{ env.DATA_DIRECTORY }}/.junit-report/integration/results.xml
          retention-days: 1
          overwrite: true

      - name: Publish Data Integration Report To Codecov
        if: ${{ !cancelled() }}
        uses: codecov/codecov-action@v5
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          files: ${{ env.DATA_DIRECTORY }}/.junit-report/integration/results.xml
          flags: data-integration
          report_type: test_results

      - name: Stop MongoDB Container
        if: ${{ always() }}
        run: docker stop sefaria-mongo || true

  website_publish_test_results_to_codecov:
    name: Publish Website Test Results To Codecov
    permissions:
      contents: read
    runs-on: ubuntu-latest
    needs: [website_e2e, website_performance]
    if: ${{ always() && (needs.website_e2e.result != 'skipped' || needs.website_performance.result != 'skipped') }}
    steps:
      - name: Checkout
        id: checkout
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event_name == 'workflow_dispatch' && github.event.inputs.ref || github.head_ref }}

      - name: Restore Website JUnit Reports
        uses: actions/download-artifact@v7
        with:
          pattern: website-*-junit-report-${{ github.run_id }}
          path: ${{ env.TMP_WEBSITE_JUNIT_REPORTS_DIRECTORY }}
          merge-multiple: true

      - name: List JUnit files
        id: list_files
        run: |
          cd ${{ env.TMP_WEBSITE_JUNIT_REPORTS_DIRECTORY }}
          files=$(ls -1 | paste -sd,)
          echo "junit_files=$files" >> $GITHUB_OUTPUT

      - name: Publish Website Unit/E2E/Perf Report To Codecov
        if: ${{ needs.website_e2e.result != 'skipped' }}
        uses: codecov/codecov-action@v5
        with:
          working-directory: ${{ env.TMP_WEBSITE_JUNIT_REPORTS_DIRECTORY }}
          token: ${{ secrets.CODECOV_TOKEN }}
          files: ${{ steps.list_files.outputs.junit_files }}
          flags: website # Assuming you want to flag these as website tests
          report_type: test_results

  cross_module_ci:
    name: Cross Module CI
    runs-on: ubuntu-latest
    needs:
      [
        determine_website_changes,
        determine_api_changes,
        determine_app_changes,
        determine_data_changes,
        verify_website_version,
        verify_api_version,
        verify_app_version,
        website_performance,
        website_e2e,
        api_e2e,
        app_ci,
        data_ci,
        build_lcov_docker,
        determine_baseline_availability,
        determine_docker_image_availability,
      ]
    if: ${{ always() }}
    steps:
      - name: Check Prerequisites
        id: check_prerequisites
        run: |
          WEBSITE_CHANGES_DETERMINATION_STATUS=$([ "${{ needs.determine_website_changes.result }}" = "success" ] && echo "success" || echo "failure") # Generated
          API_CHANGES_DETERMINATION_STATUS=$([ "${{ needs.determine_api_changes.result }}" = "success" ] && echo "success" || echo "failure") # Generated
          APP_CHANGES_DETERMINATION_STATUS=$([ "${{ needs.determine_app_changes.result }}" = "success" ] && echo "success" || echo "failure") # Generated
          DATA_CHANGES_DETERMINATION_STATUS=$([ "${{ needs.determine_data_changes.result }}" = "success" ] && echo "success" || echo "failure") # Generated
          if [ "$WEBSITE_CHANGES_DETERMINATION_STATUS" = "failure" ] || [ "$API_CHANGES_DETERMINATION_STATUS" = "failure" ] || [ "$APP_CHANGES_DETERMINATION_STATUS" = "failure" ] || [ "$DATA_CHANGES_DETERMINATION_STATUS" = "failure" ]; then
            echo "Could not determine module changes."
            [ "$WEBSITE_CHANGES_DETERMINATION_STATUS" = "failure" ] && echo " - Failed to determine website changes."
            [ "$API_CHANGES_DETERMINATION_STATUS" = "failure" ] && echo " - Failed to determine API changes."
            [ "$APP_CHANGES_DETERMINATION_STATUS" = "failure" ] && echo " - Failed to determine app changes."
            [ "$DATA_CHANGES_DETERMINATION_STATUS" = "failure" ] && echo " - Failed to determine data changes."
            echo "Overall status: failure"
            exit 1
          fi

          # Version verification checks (only fail if the job ran and failed, not if skipped)
          WEBSITE_MODULE_CHANGED=$([ "${{ needs.determine_website_changes.outputs.module_changed }}" = "true" ] && echo "true" || echo "false") # Generated
          if [ "$WEBSITE_MODULE_CHANGED" = "true" ] && [ "${{ needs.verify_website_version.result }}" = "failure" ]; then
            echo "Website version verification failed."
            echo "Overall status: failure"
            exit 1
          fi

          API_MODULE_CHANGED=$([ "${{ needs.determine_api_changes.outputs.module_changed }}" = "true" ] && echo "true" || echo "false") # Generated
          if [ "$API_MODULE_CHANGED" = "true" ] && [ "${{ needs.verify_api_version.result }}" = "failure" ]; then
            echo "API version verification failed."
            echo "Overall status: failure"
            exit 1
          fi

          APP_MODULE_CHANGED=$([ "${{ needs.determine_app_changes.outputs.module_changed }}" = "true" ] && echo "true" || echo "false") # Generated
          if [ "$APP_MODULE_CHANGED" = "true" ] && [ "${{ needs.verify_app_version.result }}" = "failure" ]; then
            echo "App version verification failed."
            echo "Overall status: failure"
            exit 1
          fi

          CI_CHANGED=$([ "${{ needs.determine_website_changes.outputs.ci_changed }}" = "true" ] && echo "true" || echo "false") # Generated
          WEBSITE_MASTER_COVERAGE_AVAILABLE=$([ "${{ needs.determine_baseline_availability.outputs.is_website_master_coverage_available }}" = "true" ] && echo "true" || echo "false") # Generated
          if [ "$WEBSITE_MODULE_CHANGED" = "true" ] || [ "$CI_CHANGED" = "true" ] || [ "$WEBSITE_MASTER_COVERAGE_AVAILABLE" = "false" ]; then
            E2E_STATUS=$([ "${{ needs.website_e2e.result }}" = "success" ] && echo "success" || echo "failure") # Generated
              PERFORMANCE_STATUS=skipped
              # No need to run performance tests if only the master coverage is available but no changes were made to niether the website nor the CI
              if [ "$WEBSITE_MODULE_CHANGED" = "true" ] || [ "$CI_CHANGED" = "true" ]; then
                PERFORMANCE_STATUS=$([ "${{ needs.website_performance.result }}" = "success" ] && echo "success" || echo "failure") # Generated
              fi
            if [ "$E2E_STATUS" = "failure" ] || [ "$PERFORMANCE_STATUS" = "failure" ]; then
              echo "Overall status: failure"
              exit 1
            fi
          fi

          API_MODULE_CHANGED=$([ "${{ needs.determine_api_changes.outputs.module_changed }}" = "true" ] && echo "true" || echo "false") # Generated
          API_MASTER_COVERAGE_AVAILABLE=$([ "${{ needs.determine_baseline_availability.outputs.is_api_master_coverage_available }}" = "false" ] && echo "true" || echo "false") # Generated
          if [ "$API_MODULE_CHANGED" = "true" ] || [ "$CI_CHANGED" = "true" ] || [ "$API_MASTER_COVERAGE_AVAILABLE" = "true" ]; then
            API_STATUS=$([ "${{ needs.api_e2e.result }}" = "success" ] && echo "success" || echo "failure") # Generated
            if [ "$API_STATUS" = "failure" ]; then
              echo "Overall status: failure"
              exit 1
            fi
          fi

          APP_MODULE_CHANGED=$([ "${{ needs.determine_app_changes.outputs.module_changed }}" = "true" ] && echo "true" || echo "false") # Generated
          APP_MASTER_COVERAGE_AVAILABLE=$([ "${{ needs.determine_baseline_availability.outputs.is_app_master_coverage_available }}" = "false" ] && echo "true" || echo "false") # Generated
          if [ "$APP_MODULE_CHANGED" = "true" ] || [ "$CI_CHANGED" = "true" ] || [ "$APP_MASTER_COVERAGE_AVAILABLE" = "true" ]; then
            APP_STATUS=$([ "${{ needs.app_ci.result }}" = "success" ] && echo "success" || echo "failure") # Generated
            if [ "$APP_STATUS" = "failure" ]; then
              echo "Overall status: failure"
              exit 1
            fi
          fi

          DATA_MODULE_CHANGED=$([ "${{ needs.determine_data_changes.outputs.module_changed }}" = "true" ] && echo "true" || echo "false") # Generated
          if [ "$DATA_MODULE_CHANGED" = "true" ] || [ "$CI_CHANGED" = "true" ]; then
            # Only fail if data_ci explicitly failed (not if skipped)
            DATA_STATUS=$([ "${{ needs.data_ci.result }}" = "failure" ] && echo "failure" || echo "success") # Generated
            if [ "$DATA_STATUS" = "failure" ]; then
              echo "Overall status: failure"
              exit 1
            fi
          fi

          echo "Overall status: success"

      - name: Checkout
        id: checkout
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event_name == 'workflow_dispatch' && github.event.inputs.ref || github.head_ref }}

      - name: Restore Website Coverage Report
        uses: actions/download-artifact@v7
        with:
          name: ${{ needs.website_e2e.result != 'skipped' && env.WEBSITE_COVERAGE_ARTIFACT_NAME_WF || env.WEBSITE_COVERAGE_ARTIFACT_NAME_MASTER }}
          path: ${{ env.WEBSITE_MERGED_COVERAGE_DIRECTORY }}

      - name: Publish Website Coverage To Codecov
        uses: codecov/codecov-action@v5
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          files: ${{ env.WEBSITE_MERGED_COVERAGE_REPORT }}
          disable_search: true
          flags: website
          fail_ci_if_error: true

      - name: Restore API Coverage Report
        uses: actions/download-artifact@v7
        with:
          name: ${{ needs.api_e2e.result != 'skipped' && env.API_COVERAGE_ARTIFACT_NAME_WF || env.API_COVERAGE_ARTIFACT_NAME_MASTER }}
          path: ${{ env.API_MERGED_COVERAGE_DIRECTORY }}

      - name: Publish API Coverage To Codecov
        uses: codecov/codecov-action@v5
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          files: ${{ env.API_COVERAGE_REPORT }}
          disable_search: true
          flags: api
          fail_ci_if_error: true

      - name: Restore App Coverage Report
        uses: actions/download-artifact@v7
        with:
          name: ${{ needs.app_ci.result != 'skipped' && env.APP_COVERAGE_ARTIFACT_NAME_WF || env.APP_COVERAGE_ARTIFACT_NAME_MASTER }}
          path: ${{ env.APP_MERGED_COVERAGE_DIRECTORY }}

      - name: Publish App Coverage To Codecov
        uses: codecov/codecov-action@v5
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          files: ${{ env.APP_COVERAGE_REPORT }}
          disable_search: true
          flags: app
          fail_ci_if_error: true

      - name: Restore lcov Docker image
        uses: actions/download-artifact@v7
        with:
          name: ${{ env.LCOV_DOCKER_IMAGE_ARTIFACT_NAME }}
          path: /tmp

      - name: Load lcov Docker image
        run: docker load --input /tmp/lcov-docker-image.tar

      - name: Setup DevOps Node.js
        id: setup-devops-node
        uses: actions/setup-node@v6
        with:
          node-version-file: ${{ env.DEVOPS_NODE_VERSION_FILE }}
          cache-dependency-path: ${{ env.DEVOPS_NODE_CACHE_PATH }}
          cache: npm

      - name: Install devops npm Dependencies
        id: devops_npm_ci
        working-directory: ${{ env.DEVOPS_DIRECTORY }}
        run: |
          npm ci --no-audit

      - name: Merge Test Coverage (Website + API)
        run: npm run coverage:merge
        working-directory: ${{ env.DEVOPS_DIRECTORY }}

      - name: Publish Cross Module Coverage To Codacy
        uses: codacy/codacy-coverage-reporter-action@master
        with:
          project-token: ${{ secrets.CODACY_PROJECT_TOKEN }}
          coverage-reports: ${{ env.CROSS_MODULE_COVERAGE_REPORT }}

      - name: Verify Coverage 3rd Party Reporting
        run: |
          # Check Codecov status using the Codecov API
            MAX_RETRIES=10
            RETRY_COUNT=0
            while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
              OWNER_REPO=(${GITHUB_REPOSITORY/\// })
              if [ "$GITHUB_EVENT_NAME" == "pull_request" ]; then
                GITHUB_SHA=$(cat $GITHUB_EVENT_PATH | jq -r .pull_request.head.sha)
              else
                GITHUB_SHA=${{ github.sha }} # Generated
              fi
              CODECOV_JSON=$(curl -s -H "Authorization: token ${{ secrets.CODECOV_API_TOKEN }}" "https://api.codecov.io/api/v2/github/${OWNER_REPO[0]}/repos/${OWNER_REPO[1]}/commits/$GITHUB_SHA") # Generated
              # Check if the response JSON has an "error" key or if the "error" value is not null/empty
              if [ "$(echo "$CODECOV_JSON" | jq -r 'has("error") and (.error != null) and (.error != "")')" = "true" ]; then
                echo "Codecov API returned error: $(echo "$CODECOV_JSON" | jq -r '.error')"
                echo "Failed to get Codecov status"
                echo "status=failure" >> $GITHUB_OUTPUT
                exit 1
              fi
              CODECOV_STATUS=$(echo "$CODECOV_JSON" | jq -r '.state')
              if [ "$CODECOV_STATUS" = "complete" ]; then
                CODECOV_RESULT=$(echo "$CODECOV_JSON" | jq -r '.ci_passed')
                if [ "$CODECOV_RESULT" = "false" ]; then
                  echo "Codecov check failed"
                  echo "status=failure" >> $GITHUB_OUTPUT
                  exit 1
                fi
                break
              fi
              if [ $RETRY_COUNT -eq $((MAX_RETRIES-1)) ]; then
                echo "Timeout waiting for Codecov status"
                echo "status=failure" >> $GITHUB_OUTPUT
                exit 1
              fi
              echo "Waiting for Codecov status to complete (attempt $((RETRY_COUNT+1))/$MAX_RETRIES)..."
              sleep 10
              RETRY_COUNT=$((RETRY_COUNT+1))
            done

  release_website:
    name: Release Website
    needs: [setup_env, determine_website_changes, cross_module_ci, package_website]
    # Note: Using always() + output check as a workaround for reusable workflow result evaluation issues (see #1065)
    # Also verify cross_module_ci and package_website passed to ensure quality gate
    if: ${{ always() && needs.cross_module_ci.result == 'success' && needs.package_website.result == 'success' && needs.package_website.outputs.module_version != '' && needs.determine_website_changes.outputs.module_changed == 'true' && needs.setup_env.outputs.is_master_branch == 'true' && github.event_name == 'push' }}
    permissions:
      contents: write
      actions: read
    secrets: inherit
    uses: ./.github/workflows/shared-release.yml
    with:
      module_name: website
      module_directory: ${{ needs.setup_env.outputs.website_directory }}
      module_version: ${{ needs.package_website.outputs.module_version }}
      artifacts_json: '[{"name": "${{ needs.package_website.outputs.docker_artifact_name }}", "path": "web/bible-on-site/.release", "glob": "*.tar.gz"}]'
      cd_event_type: deploy-aws

  release_api:
    name: Release API
    needs: [setup_env, determine_api_changes, cross_module_ci, package_api]
    # Note: Using always() + output check as a workaround for reusable workflow result evaluation issues (see #1065)
    # Also verify cross_module_ci and package_api passed to ensure quality gate
    if: ${{ always() && needs.cross_module_ci.result == 'success' && needs.package_api.result == 'success' && needs.package_api.outputs.module_version != '' && needs.determine_api_changes.outputs.module_changed == 'true' && needs.setup_env.outputs.is_master_branch == 'true' && github.event_name == 'push' }}
    permissions:
      contents: write
      actions: read
    secrets: inherit
    uses: ./.github/workflows/shared-release.yml
    with:
      module_name: api
      module_directory: ${{ needs.setup_env.outputs.api_directory }}
      module_version: ${{ needs.package_api.outputs.module_version }}
      artifacts_json: '[{"name": "${{ needs.package_api.outputs.docker_artifact_name }}", "path": "web/api/.release", "glob": "*.tar.gz"}]'
      cd_event_type: deploy-aws

  release_app:
    name: Release App
    needs: [setup_env, determine_app_changes, cross_module_ci, package_app]
    # Note: Using always() + output check as a workaround for reusable workflow result evaluation issues (see #1065)
    # Also verify cross_module_ci and package_app passed to ensure quality gate
    if: ${{ always() && needs.cross_module_ci.result == 'success' && needs.package_app.result == 'success' && needs.package_app.outputs.module_version != '' && needs.determine_app_changes.outputs.module_changed == 'true' && needs.setup_env.outputs.is_master_branch == 'true' && github.event_name == 'push' }}
    permissions:
      contents: write
      actions: read
    secrets: inherit
    uses: ./.github/workflows/shared-release.yml
    with:
      module_name: app
      module_directory: app
      module_version: ${{ needs.package_app.outputs.module_version }}
      artifacts_json: |
        [
          {"name": "${{ needs.package_app.outputs.windows_artifact_name }}", "path": "app/.artifacts/windows", "glob": "**/BibleOnSite*.msix", "label": "Windows (MSIX)", "cd_key": "windows_artifact_name"},
          {"name": "${{ needs.package_app.outputs.android_artifact_name }}", "path": "app/.artifacts/android", "glob": "**/*.aab", "label": "Android (AAB)", "cd_key": "android_artifact_name"},
          {"name": "${{ needs.package_app.outputs.ios_artifact_name }}", "path": "app/.artifacts/ios", "glob": "**/*.ipa", "label": "iOS (IPA)", "cd_key": "ios_artifact_name"}
        ]
      cd_event_type: deploy-app

  release_data:
    name: Release Data
    needs: [setup_env, determine_data_changes, cross_module_ci, data_ci]
    if: ${{ needs.data_ci.result == 'success' && needs.determine_data_changes.outputs.module_changed == 'true' && needs.setup_env.outputs.is_master_branch == 'true' && github.event_name == 'push' }}
    permissions:
      contents: read
    runs-on: ubuntu-latest
    steps:
      - name: Trigger Data CD Workflow
        uses: peter-evans/repository-dispatch@v4
        with:
          repository: ${{ github.repository }}
          token: ${{ secrets.BOT_PAT }}
          event-type: deploy-data
          client-payload: '{"ref": "${{ github.ref }}"}'

  # ====================================================================================
  # VERSION BUMP JOB - Consolidated version bumping to avoid race conditions
  # ====================================================================================
  # This job runs after all release jobs and bumps versions for all released modules
  # in a single commit/push, avoiding the race conditions that occur when multiple
  # release jobs try to push version bumps in parallel.
  # ====================================================================================
  bump_versions:
    name: Bump Versions
    needs: [setup_env, release_website, release_api, release_app]
    # Run if at least one module was released
    # Note: Using always() + result check as a workaround for reusable workflow result evaluation issues (see #1065)
    # For each release job, we check both result == 'success' AND outputs.released == 'true'
    if: >-
      ${{ always() && needs.setup_env.outputs.is_master_branch == 'true' && github.event_name == 'push' &&
      ((needs.release_website.result == 'success' && needs.release_website.outputs.released == 'true') ||
       (needs.release_api.result == 'success' && needs.release_api.outputs.released == 'true') ||
       (needs.release_app.result == 'success' && needs.release_app.outputs.released == 'true')) }}
    permissions:
      contents: write
    runs-on: ubuntu-latest
    # Single concurrency group for all version bumps to prevent any race conditions
    concurrency:
      group: ${{ github.repository }}-version-bump
      cancel-in-progress: false
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Configure Git
        run: |
          git config --global user.email "actions@github.com"
          git config --global user.name "GitHub Actions"

      - name: Add Deploy Key
        uses: webfactory/ssh-agent@72c0bfd31ab22a2e11716951e3f107a9647dc97e
        with:
          ssh-private-key: ${{ secrets.DEPLOY_KEY }}

      # Setup toolchains for modules that need version bumps
      - name: Setup Node.js (for Website)
        if: ${{ needs.release_website.outputs.released == 'true' }}
        uses: actions/setup-node@v6
        with:
          node-version-file: ${{ needs.setup_env.outputs.website_directory }}/package.json
          cache-dependency-path: ${{ needs.setup_env.outputs.website_directory }}/package-lock.json
          cache: npm

      - name: Setup Rust (for API)
        if: ${{ needs.release_api.outputs.released == 'true' }}
        uses: dtolnay/rust-toolchain@stable

      - name: Install Rust tools (for API)
        if: ${{ needs.release_api.outputs.released == 'true' }}
        uses: taiki-e/install-action@v2
        with:
          tool: cargo-make, tomato-toml, semver-bump

      - name: Setup .NET (for App)
        if: ${{ needs.release_app.outputs.released == 'true' }}
        uses: actions/setup-dotnet@v5
        with:
          dotnet-version: "9.0.x"

      - name: Restore dotnet tools (for App)
        if: ${{ needs.release_app.outputs.released == 'true' }}
        working-directory: app
        run: dotnet tool restore

      # Bump versions for each released module
      - name: Bump Website Version
        if: ${{ needs.release_website.outputs.released == 'true' }}
        working-directory: ${{ needs.setup_env.outputs.website_directory }}
        # Use --ignore-scripts to avoid running the 'version' script which requires cross-env-shell
        # The version script just echoes the version and isn't needed during the bump
        run: npm version patch --no-git-tag-version --ignore-scripts

      - name: Bump API Version
        if: ${{ needs.release_api.outputs.released == 'true' }}
        working-directory: ${{ needs.setup_env.outputs.api_directory }}
        run: cargo make bump-version

      - name: Bump App Version
        if: ${{ needs.release_app.outputs.released == 'true' }}
        working-directory: app
        run: dotnet run --project devops -- BumpVersion

      # Collect all changed files and create a single commit
      - name: Commit All Version Bumps
        run: |
          set -e

          FILES_TO_ADD=""
          MODULES_BUMPED=""

          if [ "${{ needs.release_website.outputs.released }}" = "true" ]; then
            FILES_TO_ADD="$FILES_TO_ADD ${{ needs.setup_env.outputs.website_directory }}/package.json ${{ needs.setup_env.outputs.website_directory }}/package-lock.json"
            WEBSITE_VERSION=$(node -e "const pkg = require('./${{ needs.setup_env.outputs.website_directory }}/package.json'); console.log(pkg.version)")
            MODULES_BUMPED="${MODULES_BUMPED}website to ${WEBSITE_VERSION}, "
          fi

          if [ "${{ needs.release_api.outputs.released }}" = "true" ]; then
            FILES_TO_ADD="$FILES_TO_ADD ${{ needs.setup_env.outputs.api_directory }}/Cargo.toml ${{ needs.setup_env.outputs.api_directory }}/Cargo.lock"
            API_VERSION=$(grep -m1 '^version' ${{ needs.setup_env.outputs.api_directory }}/Cargo.toml | sed 's/.*"\(.*\)"/\1/')
            MODULES_BUMPED="${MODULES_BUMPED}api to ${API_VERSION}, "
          fi

          if [ "${{ needs.release_app.outputs.released }}" = "true" ]; then
            FILES_TO_ADD="$FILES_TO_ADD app/BibleOnSite/BibleOnSite.csproj"
            APP_VERSION=$(grep -o '<ApplicationDisplayVersion>[^<]*</ApplicationDisplayVersion>' app/BibleOnSite/BibleOnSite.csproj | sed 's/<[^>]*>//g')
            MODULES_BUMPED="${MODULES_BUMPED}app to ${APP_VERSION}, "
          fi

          # Remove trailing comma and space
          MODULES_BUMPED=$(echo "$MODULES_BUMPED" | sed 's/, $//')

          if [ -n "$FILES_TO_ADD" ]; then
            git add $FILES_TO_ADD
            git checkout -- . 2>/dev/null || true
            git clean -fd 2>/dev/null || true
            git commit -n -m "chore(release): Bump versions ($MODULES_BUMPED) [skip ci]"
          else
            echo "No version files to commit"
            exit 0
          fi

      - name: Push Version Bump Changes
        run: |
          set -e
          CURRENT_BRANCH=$(git symbolic-ref --short HEAD)
          git remote set-url origin git@github.com:${{ github.repository }}
          git fetch origin "$CURRENT_BRANCH"

          # Rebase on top of any changes that happened during the release
          if ! git rebase "origin/$CURRENT_BRANCH"; then
            echo "Error: Failed to rebase version bump commit. This may indicate a conflict."
            echo "Aborting rebase..."
            git rebase --abort
            exit 1
          fi

          git push origin HEAD
